# IT伦理与道德——人工智能伦理问题
## 一、人工智能概述
    来自维基百科

人工智能（英语：Artificial Intelligence，缩写为 AI）亦称机器智能，指由人制造出来的机器所表现出来的智能。通常人工智能是指通过普通计算机程序的手段实现的人类智能技术。该词也指出研究这样的智能系统是否能够实现，以及如何实现。同时，人类的无数职业也逐渐被其取代。

![](https://upload.wikimedia.org/wikipedia/commons/1/17/ArtificialFictionBrain.png)

AI的核心问题包括建构能够跟人类似甚至超越的推理、知识、规划、学习、交流、感知、移动和操作物体的能力等。人工智能目前仍然是该领域的长远目标。目前强人工智能已经有初步成果，甚至在一些视频识别、语言分析、棋类游戏等等单方面的能力达到了超越人类的水平，而且人工智能的通用性代表着，能解决上述的问题的是一样的AI程序，无须重新开发算法就可以直接使用现有的AI完成任务，与人类的处理能力相同，但达到具备思考能力的统合强人工智能还需要时间研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。思维来源于大脑，而思维控制行为，行为需要意志去实现，而思维又是对所有数据采集的整理，相当于数据库，所以人工智能最后会演变为机器替换人类。

## 二、人工智能存在问题
史蒂芬·霍金、比尔盖茨、马斯克、 Jaan Tallinn 以及 Nick Bostrom 等人都对于人工智能技术的未来公开表示忧心，人工智能若在许多方面超越人类智能水平的智能、不断更新、自我提升，进而获取控制管理权，人类是否有足够的能力及时停止人工智能领域的“军备竞赛”，能否保有最高掌控权，现有事实是：机器常失控导致人员伤亡，这样的情况是否会更加扩大规模出现，历史显然无法给出可靠的乐观答案。特斯拉电动车马斯克（Elon Musk）在麻省理工学院（MIT）航空航天部门百年纪念研讨会上称人工智能是“召唤恶魔”行为，英国发明家Clive Sinclair认为一旦开始制造抵抗人类和超越人类的智能机器，人类可能很难生存，盖茨同意马斯克和其它人所言，且不知道为何有些人不担忧这个问题。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Innorobo_2015_-_NAO_%28cropped%29.JPG/330px-Innorobo_2015_-_NAO_%28cropped%29.JPG)

## 三、人工智能“自主武器”问题
科技进步，人工智能科技产生“自主武器”军备竞赛已悄悄展开，英国、以色列与挪威，都已部署自主导弹与无人操控的无人机，具“射后不理”（fire-and-forget）能力的导弹，多枚导弹还可互相沟通，分享找到攻击目标。这些武器还未被大量投入，但很快就会出现在战场上，且并非使用人类所设计的程序，而是完全利用机器自行决策。霍金等人在英国独立报发表文章警告未来人工智能可能会比人类金融市场、科学家、人类领袖更能操纵人心、甚至研发出人们无法理解的武器。专家恐发展到无法控制的局面，援引联合国禁止研发某些特定武器的“特定常规武器公约”加以限制。新南威尔士大学（New South Wales）人工智能的沃尔什（Toby Walsh）教授认为这是一种欺骗，因为机器无区别战敌和平民的技术。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/L%27uomo_meccanico_1.png/330px-L%27uomo_meccanico_1.png)

## 四、人工智能引发经济冲击
据CNN财经网数字媒体未来学家兼Webbmedia集团创始人艾米·韦伯（Amy Webb）；美国在线等纷纷预测一些即将被机器人取代的职业，日本野村总合研究所也与英国牛津大学的研究学者共同调查指出，10至20年后，日本有49%的职业(235种职业)可能会被机械和人工智能取代而消失，直接影响约达2500万人，例如：超市店员、一般事务员、计程车司机、收费站运营商和收银员、市场营销人员、客服人员、制造业工人、金融中间人和分析师、新闻记者、电话公司职员、麻醉师、士兵和保安、律师、医生、软件开发者和操盘手、股票交易员等等高薪酬的脑力职业将最先受到冲击。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Automation_of_foundry_with_robot.jpg/330px-Automation_of_foundry_with_robot.jpg)

## 五、强人工智能争论
关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。他举了个中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/TOPIO_3.jpg/330px-TOPIO_3.jpg)

也有哲学家持不同的观点。丹尼尔·丹尼特在其著作《意识的解释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。

有的哲学家认为如果弱人工智能是可实现的，那么强人工智能也是可实现的。比如西蒙·布莱克本（Simon Blackburn）在其哲学入门教材Think里说道，一个人的看起来是“智能”的行动并不能真正说明这个人就真的是智能的。我永远不可能知道另一个人是否真的像我一样是智能的，还是说她／他仅仅是“看起来”是智能的。基于这个论点，既然弱人工智能认为可以令机器“看起来”像是智能的，那就不能完全否定这机器是真的有智能的。布莱克本认为这是一个主观认定的问题。
